{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b7d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LEGAL CLAUSE SIMILARITY DETECTION\n",
      "Deep Learning Assignment 2 - NUCES FAST\n",
      "WITH PARALLEL PROCESSING (100-500x FASTER)\n",
      "================================================================================\n",
      "PyTorch Version: 2.9.0+cu128\n",
      "Device: cuda\n",
      "CPU Cores Available: 16\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STARTING LEGAL CLAUSE SIMILARITY DETECTION PIPELINE\n",
      "WITH PARALLEL PROCESSING FOR 100-500x SPEED IMPROVEMENT\n",
      "================================================================================\n",
      "\n",
      "[STEP 1/6] Data Loading and Preprocessing\n",
      "\n",
      "================================================================================\n",
      "DATA PREPROCESSING PIPELINE\n",
      "================================================================================\n",
      "Found 395 CSV files\n",
      "  âœ“ Loaded: permits.csv - 350 clauses\n",
      "  âœ“ Loaded: indemnity.csv - 240 clauses\n",
      "  âœ“ Loaded: subordination.csv - 290 clauses\n",
      "  âœ“ Loaded: capitalization.csv - 200 clauses\n",
      "  âœ“ Loaded: adjustments.csv - 360 clauses\n",
      "  âœ“ Loaded: registration-procedures.csv - 500 clauses\n",
      "  âœ“ Loaded: relationship-of-parties.csv - 440 clauses\n",
      "  âœ“ Loaded: w-i-t-n-e-s-s-e-t-h-whereas.csv - 470 clauses\n",
      "  âœ“ Loaded: general-provisions.csv - 290 clauses\n",
      "  âœ“ Loaded: rent.csv - 340 clauses\n",
      "  âœ“ Loaded: investment-company-act.csv - 500 clauses\n",
      "  âœ“ Loaded: legend.csv - 330 clauses\n",
      "  âœ“ Loaded: severability.csv - 370 clauses\n",
      "  âœ“ Loaded: participations.csv - 210 clauses\n",
      "  âœ“ Loaded: representations-and-warranties.csv - 420 clauses\n",
      "  âœ“ Loaded: complete-agreement.csv - 420 clauses\n",
      "  âœ“ Loaded: modification-and-waiver.csv - 420 clauses\n",
      "  âœ“ Loaded: scope.csv - 420 clauses\n",
      "  âœ“ Loaded: restrictions-on-transfer.csv - 330 clauses\n",
      "  âœ“ Loaded: accounting-terms.csv - 370 clauses\n",
      "  âœ“ Loaded: contribution.csv - 180 clauses\n",
      "  âœ“ Loaded: sick-leave.csv - 450 clauses\n",
      "  âœ“ Loaded: change-of-control.csv - 370 clauses\n",
      "  âœ“ Loaded: rules-of-construction.csv - 410 clauses\n",
      "  âœ“ Loaded: access-to-information.csv - 270 clauses\n",
      "  âœ“ Loaded: fees_royalties.csv - 123 clauses\n",
      "  âœ“ Loaded: inspection.csv - 340 clauses\n",
      "  âœ“ Loaded: disability.csv - 330 clauses\n",
      "  âœ“ Loaded: other-benefits.csv - 410 clauses\n",
      "  âœ“ Loaded: usa-patriot-act.csv - 330 clauses\n",
      "  âœ“ Loaded: duration.csv - 450 clauses\n",
      "  âœ“ Loaded: set-off.csv - 350 clauses\n",
      "  âœ“ Loaded: reports.csv - 360 clauses\n",
      "  âœ“ Loaded: certain-defined-terms.csv - 550 clauses\n",
      "  âœ“ Loaded: exercise-of-option.csv - 350 clauses\n",
      "  âœ“ Loaded: consent-to-jurisdiction.csv - 300 clauses\n",
      "  âœ“ Loaded: descriptive-headings.csv - 480 clauses\n",
      "  âœ“ Loaded: parking.csv - 360 clauses\n",
      "  âœ“ Loaded: recitals.csv - 440 clauses\n",
      "  âœ“ Loaded: restrictions.csv - 360 clauses\n",
      "  âœ“ Loaded: erisa.csv - 320 clauses\n",
      "  âœ“ Loaded: effect-of-termination.csv - 360 clauses\n",
      "  âœ“ Loaded: maintenance-of-office-or-agency.csv - 340 clauses\n",
      "  âœ“ Loaded: dividends.csv - 350 clauses\n",
      "  âœ“ Loaded: registration-expenses.csv - 310 clauses\n",
      "  âœ“ Loaded: other.csv - 420 clauses\n",
      "  âœ“ Loaded: therefore.csv - 510 clauses\n",
      "  âœ“ Loaded: benefits.csv - 410 clauses\n",
      "  âœ“ Loaded: investments.csv - 410 clauses\n",
      "  âœ“ Loaded: waivers.csv - 390 clauses\n",
      "  âœ“ Loaded: use-of-proceeds.csv - 430 clauses\n",
      "  âœ“ Loaded: fractional-shares.csv - 400 clauses\n",
      "  âœ“ Loaded: ownership.csv - 350 clauses\n",
      "  âœ“ Loaded: definitions.csv - 560 clauses\n",
      "  âœ“ Loaded: confidential-information.csv - 240 clauses\n",
      "  âœ“ Loaded: dispute-resolution.csv - 310 clauses\n",
      "  âœ“ Loaded: in-witness-whereof.csv - 250 clauses\n",
      "  âœ“ Loaded: capitalized-terms.csv - 590 clauses\n",
      "  âœ“ Loaded: judgments.csv - 430 clauses\n",
      "  âœ“ Loaded: relationship-of-the-parties.csv - 420 clauses\n",
      "  âœ“ Loaded: validity.csv - 450 clauses\n",
      "  âœ“ Loaded: other-remedies.csv - 380 clauses\n",
      "  âœ“ Loaded: cooperation.csv - 350 clauses\n",
      "  âœ“ Loaded: covenants.csv - 460 clauses\n",
      "  âœ“ Loaded: intellectual-property.csv - 250 clauses\n",
      "  âœ“ Loaded: term-of-agreement.csv - 380 clauses\n",
      "  âœ“ Loaded: limitation-on-liability.csv - 330 clauses\n",
      "  âœ“ Loaded: negative-covenants.csv - 500 clauses\n",
      "  âœ“ Loaded: base-salary.csv - 380 clauses\n",
      "  âœ“ Loaded: change-in-control.csv - 380 clauses\n",
      "  âœ“ Loaded: partial-invalidity.csv - 470 clauses\n",
      "  âœ“ Loaded: compensation.csv - 400 clauses\n",
      "  âœ“ Loaded: additional-agreements.csv - 400 clauses\n",
      "  âœ“ Loaded: resignation.csv - 420 clauses\n",
      "  âœ“ Loaded: transactions-with-affiliates.csv - 300 clauses\n",
      "  âœ“ Loaded: specific-performance.csv - 350 clauses\n",
      "  âœ“ Loaded: defined-terms.csv - 560 clauses\n",
      "  âœ“ Loaded: no-third-party-beneficiaries.csv - 490 clauses\n",
      "  âœ“ Loaded: guaranty.csv - 330 clauses\n",
      "  âœ“ Loaded: default.csv - 370 clauses\n",
      "  âœ“ Loaded: voting-rights.csv - 400 clauses\n",
      "  âœ“ Loaded: insurance.csv - 310 clauses\n",
      "  âœ“ Loaded: powers.csv - 420 clauses\n",
      "  âœ“ Loaded: representations-and-warranties-of-seller.csv - 460 clauses\n",
      "  âœ“ Loaded: organization-and-good-standing.csv - 390 clauses\n",
      "  âœ“ Loaded: parties.csv - 450 clauses\n",
      "  âœ“ Loaded: duration-and-termination.csv - 370 clauses\n",
      "  âœ“ Loaded: other-agreements.csv - 420 clauses\n",
      "  âœ“ Loaded: liabilities.csv - 380 clauses\n",
      "  âœ“ Loaded: defaults-and-remedies.csv - 310 clauses\n",
      "  âœ“ Loaded: full-disclosure.csv - 370 clauses\n",
      "  âœ“ Loaded: notices-etc.csv - 300 clauses\n",
      "  âœ“ Loaded: organization.csv - 410 clauses\n",
      "  âœ“ Loaded: employment.csv - 430 clauses\n",
      "  âœ“ Loaded: termination-of-employment.csv - 410 clauses\n",
      "  âœ“ Loaded: conditions-precedent.csv - 520 clauses\n",
      "  âœ“ Loaded: title.csv - 350 clauses\n",
      "  âœ“ Loaded: legends.csv - 350 clauses\n",
      "  âœ“ Loaded: duration-of-agreement.csv - 400 clauses\n",
      "  âœ“ Loaded: severability-of-provisions.csv - 440 clauses\n",
      "  âœ“ Loaded: liability.csv - 380 clauses\n",
      "  âœ“ Loaded: parties-in-interest.csv - 430 clauses\n",
      "  âœ“ Loaded: notice-of-defaults.csv - 410 clauses\n",
      "  âœ“ Loaded: amendment-waiver.csv - 380 clauses\n",
      "  âœ“ Loaded: interpretation.csv - 380 clauses\n",
      "  âœ“ Loaded: further-assurances.csv - 390 clauses\n",
      "  âœ“ Loaded: attorneys-fees.csv - 450 clauses\n",
      "  âœ“ Loaded: grant-of-option.csv - 400 clauses\n",
      "  âœ“ Loaded: termination-for-cause.csv - 360 clauses\n",
      "  âœ“ Loaded: waiver-of-past-defaults.csv - 420 clauses\n",
      "  âœ“ Loaded: security-interest.csv - 310 clauses\n",
      "  âœ“ Loaded: limitations.csv - 380 clauses\n",
      "  âœ“ Loaded: documents.csv - 470 clauses\n",
      "  âœ“ Loaded: conditions-to-effectiveness.csv - 530 clauses\n",
      "  âœ“ Loaded: access.csv - 310 clauses\n",
      "  âœ“ Loaded: reporting-requirements.csv - 480 clauses\n",
      "  âœ“ Loaded: miscellaneous-provisions.csv - 330 clauses\n",
      "  âœ“ Loaded: notice-of-default.csv - 410 clauses\n",
      "  âœ“ Loaded: bonus.csv - 360 clauses\n",
      "  âœ“ Loaded: jurisdiction.csv - 370 clauses\n",
      "  âœ“ Loaded: term-and-termination.csv - 370 clauses\n",
      "  âœ“ Loaded: public-announcements.csv - 330 clauses\n",
      "  âœ“ Loaded: section-headings.csv - 570 clauses\n",
      "  âœ“ Loaded: name.csv - 540 clauses\n",
      "  âœ“ Loaded: fiscal-year.csv - 510 clauses\n",
      "  âœ“ Loaded: choice-of-law.csv - 490 clauses\n",
      "  âœ“ Loaded: consents-and-approvals.csv - 350 clauses\n",
      "  âœ“ Loaded: defaults.csv - 430 clauses\n",
      "  âœ“ Loaded: entire-agreement-amendments.csv - 370 clauses\n",
      "  âœ“ Loaded: covenants-of-the-company.csv - 540 clauses\n",
      "  âœ“ Loaded: survival-of-representations-and-warranties.csv - 400 clauses\n",
      "  âœ“ Loaded: financial-covenants.csv - 560 clauses\n",
      "  âœ“ Loaded: certain-definitions.csv - 520 clauses\n",
      "  âœ“ Loaded: notification.csv - 380 clauses\n",
      "  âœ“ Loaded: successors-and-assigns.csv - 410 clauses\n",
      "  âœ“ Loaded: assignment.csv - 400 clauses\n",
      "  âœ“ Loaded: background.csv - 380 clauses\n",
      "  âœ“ Loaded: now-therefore.csv - 570 clauses\n",
      "  âœ“ Loaded: amendments.csv - 460 clauses\n",
      "  âœ“ Loaded: warranty.csv - 350 clauses\n",
      "  âœ“ Loaded: waiver.csv - 400 clauses\n",
      "  âœ“ Loaded: time.csv - 480 clauses\n",
      "  âœ“ Loaded: interest.csv - 330 clauses\n",
      "  âœ“ Loaded: binding-effect.csv - 500 clauses\n",
      "  âœ“ Loaded: no-default.csv - 500 clauses\n",
      "  âœ“ Loaded: term.csv - 400 clauses\n",
      "  âœ“ Loaded: indebtedness.csv - 330 clauses\n",
      "  âœ“ Loaded: title-to-assets.csv - 360 clauses\n",
      "  âœ“ Loaded: stock-options.csv - 290 clauses\n",
      "  âœ“ Loaded: construction.csv - 410 clauses\n",
      "  âœ“ Loaded: letters-of-credit.csv - 290 clauses\n",
      "  âœ“ Loaded: reliance.csv - 340 clauses\n",
      "  âœ“ Loaded: method-of-payment.csv - 310 clauses\n",
      "  âœ“ Loaded: definition.csv - 400 clauses\n",
      "  âœ“ Loaded: captions.csv - 580 clauses\n",
      "  âœ“ Loaded: introduction.csv - 330 clauses\n",
      "  âœ“ Loaded: entire-agreement-amendment.csv - 380 clauses\n",
      "  âœ“ Loaded: delegation-of-duties.csv - 380 clauses\n",
      "  âœ“ Loaded: payment-of-obligations.csv - 410 clauses\n",
      "  âœ“ Loaded: dissolution.csv - 480 clauses\n",
      "  âœ“ Loaded: representations-and-warranties-of-the-company.csv - 470 clauses\n",
      "  âœ“ Loaded: injunctive-relief.csv - 360 clauses\n",
      "  âœ“ Loaded: recognition.csv - 430 clauses\n",
      "  âœ“ Loaded: exceptions.csv - 400 clauses\n",
      "  âœ“ Loaded: subsidiaries.csv - 320 clauses\n",
      "  âœ“ Loaded: governing-law-jurisdiction.csv - 350 clauses\n",
      "  âœ“ Loaded: transfers.csv - 380 clauses\n",
      "  âœ“ Loaded: bankruptcy.csv - 360 clauses\n",
      "  âœ“ Loaded: execution.csv - 460 clauses\n",
      "  âœ“ Loaded: no-conflicts.csv - 260 clauses\n",
      "  âœ“ Loaded: financial-information.csv - 330 clauses\n",
      "  âœ“ Loaded: obligations-absolute.csv - 320 clauses\n",
      "  âœ“ Loaded: costs.csv - 480 clauses\n",
      "  âœ“ Loaded: purchase-price.csv - 460 clauses\n",
      "  âœ“ Loaded: seniority.csv - 470 clauses\n",
      "  âœ“ Loaded: indemnification.csv - 210 clauses\n",
      "  âœ“ Loaded: whereas.csv - 510 clauses\n",
      "  âœ“ Loaded: compensation-and-benefits.csv - 430 clauses\n",
      "  âœ“ Loaded: remedies-cumulative.csv - 440 clauses\n",
      "  âœ“ Loaded: persons-deemed-owners.csv - 440 clauses\n",
      "  âœ“ Loaded: conduct-of-business.csv - 350 clauses\n",
      "  âœ“ Loaded: support.csv - 430 clauses\n",
      "  âœ“ Loaded: event-of-default.csv - 500 clauses\n",
      "  âœ“ Loaded: tax-matters.csv - 310 clauses\n",
      "  âœ“ Loaded: vesting.csv - 400 clauses\n",
      "  âœ“ Loaded: representations.csv - 400 clauses\n",
      "  âœ“ Loaded: registration-rights.csv - 380 clauses\n",
      "  âœ“ Loaded: licenses.csv - 390 clauses\n",
      "  âœ“ Loaded: good-reason.csv - 430 clauses\n",
      "  âœ“ Loaded: effectiveness.csv - 480 clauses\n",
      "  âœ“ Loaded: records.csv - 370 clauses\n",
      "  âœ“ Loaded: other-provisions.csv - 400 clauses\n",
      "  âœ“ Loaded: payments.csv - 370 clauses\n",
      "  âœ“ Loaded: non-discrimination.csv - 410 clauses\n",
      "  âœ“ Loaded: maintenance-of-properties.csv - 400 clauses\n",
      "  âœ“ Loaded: reimbursement-of-expenses.csv - 400 clauses\n",
      "  âœ“ Loaded: agreement.csv - 500 clauses\n",
      "  âœ“ Loaded: financial-statements.csv - 250 clauses\n",
      "  âœ“ Loaded: voting.csv - 360 clauses\n",
      "  âœ“ Loaded: holidays.csv - 430 clauses\n",
      "  âœ“ Loaded: cancellation.csv - 370 clauses\n",
      "  âœ“ Loaded: definitions-and-interpretation.csv - 590 clauses\n",
      "  âœ“ Loaded: security.csv - 380 clauses\n",
      "  âœ“ Loaded: disputes.csv - 350 clauses\n",
      "  âœ“ Loaded: withholding-taxes.csv - 320 clauses\n",
      "  âœ“ Loaded: liens.csv - 400 clauses\n",
      "  âœ“ Loaded: payment-terms.csv - 370 clauses\n",
      "  âœ“ Loaded: trustee-may-file-proofs-of-claim.csv - 132 clauses\n",
      "  âœ“ Loaded: litigation.csv - 350 clauses\n",
      "  âœ“ Loaded: non-solicitation.csv - 280 clauses\n",
      "  âœ“ Loaded: payment-of-expenses.csv - 240 clauses\n",
      "  âœ“ Loaded: force-majeure.csv - 330 clauses\n",
      "  âœ“ Loaded: confidentiality.csv - 220 clauses\n",
      "  âœ“ Loaded: solvency.csv - 400 clauses\n",
      "  âœ“ Loaded: intellectual-property-rights.csv - 290 clauses\n",
      "  âœ“ Loaded: enforceability.csv - 420 clauses\n",
      "  âœ“ Loaded: redemption.csv - 360 clauses\n",
      "  âœ“ Loaded: salary.csv - 400 clauses\n",
      "  âœ“ Loaded: governing-law-and-jurisdiction.csv - 430 clauses\n",
      "  âœ“ Loaded: preamble.csv - 350 clauses\n",
      "  âœ“ Loaded: compliance.csv - 350 clauses\n",
      "  âœ“ Loaded: duties.csv - 350 clauses\n",
      "  âœ“ Loaded: assignability.csv - 430 clauses\n",
      "  âœ“ Loaded: management-rights.csv - 430 clauses\n",
      "  âœ“ Loaded: insolvency.csv - 410 clauses\n",
      "  âœ“ Loaded: person.csv - 450 clauses\n",
      "  âœ“ Loaded: applicable-law.csv - 420 clauses\n",
      "  âœ“ Loaded: headings.csv - 570 clauses\n",
      "  âœ“ Loaded: cause.csv - 370 clauses\n",
      "  âœ“ Loaded: notices.csv - 300 clauses\n",
      "  âœ“ Loaded: arbitration.csv - 240 clauses\n",
      "  âœ“ Loaded: effect-of-headings.csv - 290 clauses\n",
      "  âœ“ Loaded: costs-and-expenses.csv - 320 clauses\n",
      "  âœ“ Loaded: terms.csv - 450 clauses\n",
      "  âœ“ Loaded: power-of-attorney.csv - 300 clauses\n",
      "  âœ“ Loaded: exclusivity.csv - 340 clauses\n",
      "  âœ“ Loaded: collateral.csv - 380 clauses\n",
      "  âœ“ Loaded: corporate-existence.csv - 430 clauses\n",
      "  âœ“ Loaded: r-e-c-i-t-a-l-s.csv - 420 clauses\n",
      "  âœ“ Loaded: appointment.csv - 360 clauses\n",
      "  âœ“ Loaded: listing.csv - 470 clauses\n",
      "  âœ“ Loaded: governing-law.csv - 460 clauses\n",
      "  âœ“ Loaded: waiver-of-jury-trial.csv - 350 clauses\n",
      "  âœ“ Loaded: authority.csv - 330 clauses\n",
      "  âœ“ Loaded: survival.csv - 430 clauses\n",
      "  âœ“ Loaded: real-property.csv - 320 clauses\n",
      "  âœ“ Loaded: application-of-proceeds.csv - 420 clauses\n",
      "  âœ“ Loaded: use.csv - 380 clauses\n",
      "  âœ“ Loaded: publicity.csv - 360 clauses\n",
      "  âœ“ Loaded: legal-proceedings.csv - 370 clauses\n",
      "  âœ“ Loaded: termination-of-agreement.csv - 420 clauses\n",
      "  âœ“ Loaded: management.csv - 360 clauses\n",
      "  âœ“ Loaded: no-solicitation.csv - 270 clauses\n",
      "  âœ“ Loaded: third-party-beneficiaries.csv - 460 clauses\n",
      "  âœ“ Loaded: disclaimer.csv - 330 clauses\n",
      "  âœ“ Loaded: no-waiver.csv - 450 clauses\n",
      "  âœ“ Loaded: limited_liability.csv - 320 clauses\n",
      "  âœ“ Loaded: termination-without-cause.csv - 350 clauses\n",
      "  âœ“ Loaded: the-merger.csv - 380 clauses\n",
      "  âœ“ Loaded: effective-date.csv - 530 clauses\n",
      "  âœ“ Loaded: amendments-etc.csv - 340 clauses\n",
      "  âœ“ Loaded: absence-of-certain-changes-or-events.csv - 350 clauses\n",
      "  âœ“ Loaded: brokerage.csv - 380 clauses\n",
      "  âœ“ Loaded: non-competition.csv - 260 clauses\n",
      "  âœ“ Loaded: termination.csv - 360 clauses\n",
      "  âœ“ Loaded: no-conflict.csv - 320 clauses\n",
      "  âœ“ Loaded: environmental-laws.csv - 320 clauses\n",
      "  âœ“ Loaded: payment.csv - 330 clauses\n",
      "  âœ“ Loaded: marketing.csv - 48 clauses\n",
      "  âœ“ Loaded: vacation.csv - 490 clauses\n",
      "  âœ“ Loaded: warranties.csv - 390 clauses\n",
      "  âœ“ Loaded: exclusions.csv - 410 clauses\n",
      "  âœ“ Loaded: meetings.csv - 370 clauses\n",
      "  âœ“ Loaded: employee-benefit-plans.csv - 290 clauses\n",
      "  âœ“ Loaded: absence-of-certain-changes.csv - 350 clauses\n",
      "  âœ“ Loaded: entire-agreement.csv - 440 clauses\n",
      "  âœ“ Loaded: representations-warranties-and-covenants.csv - 400 clauses\n",
      "  âœ“ Loaded: submission-to-jurisdiction.csv - 290 clauses\n",
      "  âœ“ Loaded: integration.csv - 430 clauses\n",
      "  âœ“ Loaded: expenses.csv - 300 clauses\n",
      "  âœ“ Loaded: condemnation.csv - 290 clauses\n",
      "  âœ“ Loaded: procedure.csv - 320 clauses\n",
      "  âœ“ Loaded: proprietary_rights.csv - 310 clauses\n",
      "  âœ“ Loaded: amendment-and-waiver.csv - 400 clauses\n",
      "  âœ“ Loaded: reimbursement.csv - 310 clauses\n",
      "  âœ“ Loaded: taxes.csv - 280 clauses\n",
      "  âœ“ Loaded: authorization.csv - 340 clauses\n",
      "  âœ“ Loaded: brokers.csv - 440 clauses\n",
      "  âœ“ Loaded: delivery.csv - 410 clauses\n",
      "  âœ“ Loaded: notice.csv - 320 clauses\n",
      "  âœ“ Loaded: bereavement-leave.csv - 380 clauses\n",
      "  âœ“ Loaded: amendments-waivers.csv - 370 clauses\n",
      "  âœ“ Loaded: security-deposit.csv - 270 clauses\n",
      "  âœ“ Loaded: agreements.csv - 480 clauses\n",
      "  âœ“ Loaded: non-disparagement.csv - 350 clauses\n",
      "  âœ“ Loaded: contracts.csv - 320 clauses\n",
      "  âœ“ Loaded: disclosure.csv - 320 clauses\n",
      "  âœ“ Loaded: tax-returns.csv - 140 clauses\n",
      "  âœ“ Loaded: witnesseth.csv - 400 clauses\n",
      "  âœ“ Loaded: events-of-default.csv - 460 clauses\n",
      "  âœ“ Loaded: loans.csv - 380 clauses\n",
      "  âœ“ Loaded: time-of-essence.csv - 630 clauses\n",
      "  âœ“ Loaded: purchase-and-sale.csv - 390 clauses\n",
      "  âœ“ Loaded: approvals.csv - 410 clauses\n",
      "  âœ“ Loaded: standard-terms-and-conditions-of-trust.csv - 15 clauses\n",
      "  âœ“ Loaded: amendment.csv - 370 clauses\n",
      "  âœ“ Loaded: additional-documents.csv - 470 clauses\n",
      "  âœ“ Loaded: optional_renewal.csv - 360 clauses\n",
      "  âœ“ Loaded: utilities.csv - 370 clauses\n",
      "  âœ“ Loaded: transfer.csv - 390 clauses\n",
      "  âœ“ Loaded: officers-certificate.csv - 400 clauses\n",
      "  âœ“ Loaded: payment-of-taxes.csv - 350 clauses\n",
      "  âœ“ Loaded: general.csv - 340 clauses\n",
      "  âœ“ Loaded: employee-benefits.csv - 310 clauses\n",
      "  âœ“ Loaded: conditions.csv - 480 clauses\n",
      "  âœ“ Loaded: amendments-and-waivers.csv - 330 clauses\n",
      "  âœ“ Loaded: no-assignment.csv - 480 clauses\n",
      "  âœ“ Loaded: release.csv - 250 clauses\n",
      "  âœ“ Loaded: increased-costs.csv - 380 clauses\n",
      "  âœ“ Loaded: investment-company.csv - 500 clauses\n",
      "  âœ“ Loaded: witnesseth-that.csv - 279 clauses\n",
      "  âœ“ Loaded: death.csv - 430 clauses\n",
      "  âœ“ Loaded: financing.csv - 350 clauses\n",
      "  âœ“ Loaded: grant-of-security-interest.csv - 320 clauses\n",
      "  âœ“ Loaded: compliance-with-laws.csv - 370 clauses\n",
      "  âœ“ Loaded: certificates.csv - 390 clauses\n",
      "  âœ“ Loaded: right-of-setoff.csv - 310 clauses\n",
      "  âœ“ Loaded: notice-of-redemption.csv - 370 clauses\n",
      "  âœ“ Loaded: labor-matters.csv - 320 clauses\n",
      "  âœ“ Loaded: indemnification-by-the-company.csv - 230 clauses\n",
      "  âœ“ Loaded: the-closing.csv - 390 clauses\n",
      "  âœ“ Loaded: officers.csv - 390 clauses\n",
      "  âœ“ Loaded: merger.csv - 420 clauses\n",
      "  âœ“ Loaded: special-terms-and-conditions-of-trust.csv - 530 clauses\n",
      "  âœ“ Loaded: information.csv - 370 clauses\n",
      "  âœ“ Loaded: acceleration.csv - 350 clauses\n",
      "  âœ“ Loaded: severance.csv - 360 clauses\n",
      "  âœ“ Loaded: no-material-adverse-change.csv - 390 clauses\n",
      "  âœ“ Loaded: employees.csv - 310 clauses\n",
      "  âœ“ Loaded: exhibits.csv - 570 clauses\n",
      "  âœ“ Loaded: compliance-with-law.csv - 400 clauses\n",
      "  âœ“ Loaded: conflict-of-interest.csv - 390 clauses\n",
      "  âœ“ Loaded: environmental-matters.csv - 270 clauses\n",
      "  âœ“ Loaded: remedies.csv - 310 clauses\n",
      "  âœ“ Loaded: closing-date.csv - 410 clauses\n",
      "  âœ“ Loaded: subrogation.csv - 330 clauses\n",
      "  âœ“ Loaded: guarantee.csv - 340 clauses\n",
      "  âœ“ Loaded: fees-and-expenses.csv - 370 clauses\n",
      "  âœ“ Loaded: grievance-procedure.csv - 440 clauses\n",
      "  âœ“ Loaded: affirmative-covenants.csv - 500 clauses\n",
      "  âœ“ Loaded: auto_renewal.csv - 383 clauses\n",
      "  âœ“ Loaded: power-and-authority.csv - 390 clauses\n",
      "  âœ“ Loaded: consents.csv - 390 clauses\n",
      "  âœ“ Loaded: term-of-employment.csv - 370 clauses\n",
      "  âœ“ Loaded: miscellaneous.csv - 300 clauses\n",
      "  âœ“ Loaded: time-of-the-essence.csv - 620 clauses\n",
      "  âœ“ Loaded: indemnification-and-contribution.csv - 180 clauses\n",
      "  âœ“ Loaded: modifications.csv - 490 clauses\n",
      "  âœ“ Loaded: organization-and-qualification.csv - 320 clauses\n",
      "  âœ“ Loaded: material-contracts.csv - 330 clauses\n",
      "  âœ“ Loaded: restricted-payments.csv - 350 clauses\n",
      "  âœ“ Loaded: reporting.csv - 410 clauses\n",
      "  âœ“ Loaded: fees.csv - 310 clauses\n",
      "  âœ“ Loaded: no-violation.csv - 340 clauses\n",
      "  âœ“ Loaded: books-and-records.csv - 370 clauses\n",
      "  âœ“ Loaded: restrictive-covenants.csv - 360 clauses\n",
      "  âœ“ Loaded: registration.csv - 320 clauses\n",
      "  âœ“ Loaded: tax-withholding.csv - 370 clauses\n",
      "  âœ“ Loaded: notice-of-termination.csv - 420 clauses\n",
      "  âœ“ Loaded: undertaking-for-costs.csv - 182 clauses\n",
      "  âœ“ Loaded: performance.csv - 460 clauses\n",
      "  âœ“ Loaded: modification.csv - 470 clauses\n",
      "  âœ“ Loaded: enforcement.csv - 340 clauses\n",
      "  âœ“ Loaded: generally.csv - 330 clauses\n",
      "  âœ“ Loaded: reinstatement.csv - 350 clauses\n",
      "  âœ“ Loaded: currency.csv - 540 clauses\n",
      "  âœ“ Loaded: successors.csv - 470 clauses\n",
      "  âœ“ Loaded: consideration.csv - 450 clauses\n",
      "  âœ“ Loaded: purpose.csv - 470 clauses\n",
      "  âœ“ Loaded: services.csv - 400 clauses\n",
      "  âœ“ Loaded: maintenance-of-insurance.csv - 360 clauses\n",
      "  âœ“ Loaded: no-strict-construction.csv - 399 clauses\n",
      "  âœ“ Loaded: assignments.csv - 380 clauses\n",
      "  âœ“ Loaded: compliance-certificate.csv - 380 clauses\n",
      "  âœ“ Loaded: standard-of-care.csv - 360 clauses\n",
      "  âœ“ Loaded: bank-accounts.csv - 430 clauses\n",
      "  âœ“ Loaded: closing.csv - 340 clauses\n",
      "  âœ“ Loaded: illegality.csv - 300 clauses\n",
      "  âœ“ Loaded: counterparts.csv - 490 clauses\n",
      "  âœ“ Loaded: limitation-of-liability.csv - 320 clauses\n",
      "  âœ“ Loaded: execution-in-counterparts.csv - 470 clauses\n",
      "  âœ“ Loaded: withholding.csv - 390 clauses\n",
      "  âœ“ Loaded: distributions.csv - 370 clauses\n",
      "  âœ“ Loaded: independent-contractor.csv - 370 clauses\n",
      "  âœ“ Loaded: position-and-duties.csv - 350 clauses\n",
      "\n",
      "ðŸ“Š Total: 150881 clauses from 395 categories\n",
      "\n",
      "Cleaning text data...\n",
      "\n",
      "ðŸ“Š Dataset Statistics:\n",
      "  - Total clauses: 150881\n",
      "  - Unique categories: 395\n",
      "\n",
      "ðŸš€ Creating pairs using PARALLEL PROCESSING...\n",
      "  - Categories: 395\n",
      "  - CPU cores: 16\n",
      "  - Max pairs per category: 500\n",
      "  âœ“ Created 197105 positive pairs in 100.73s\n",
      "  Creating negative pairs...\n",
      "  âœ“ Created 197105 negative pairs\n",
      "  âœ“ Total: 394210 pairs\n",
      "  âœ“ Balance: 50.0% positive\n",
      "\n",
      "ðŸ“š Building vocabulary...\n",
      "  - Vocabulary size: 10000\n",
      "  - Max sequence length: 150\n",
      "\n",
      "ðŸ”¢ Converting texts to sequences...\n",
      "  - Sequence 1 shape: (394210, 150)\n",
      "  - Sequence 2 shape: (394210, 150)\n",
      "  - Labels shape: (394210,)\n",
      "\n",
      "âœ“ Preprocessing complete!\n",
      "\n",
      "================================================================================\n",
      "[STEP 2/6] Creating Train/Validation/Test Splits\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Data Split:\n",
      "  - Training:   252294 samples (64.0%)\n",
      "  - Validation: 63074 samples (16.0%)\n",
      "  - Test:       78842 samples (20.0%)\n",
      "  - Batch size: 32\n",
      "  - Train batches: 7885\n",
      "  - Val batches: 1972\n",
      "  - Test batches: 2464\n",
      "\n",
      "================================================================================\n",
      "[STEP 3/6] Training Model 1: BiLSTM Siamese Network\n",
      "================================================================================\n",
      "\n",
      "ðŸ—ï¸  Model 1 Architecture:\n",
      "  - Total parameters: 1,486,977\n",
      "  - Trainable parameters: 1,486,977\n",
      "\n",
      "================================================================================\n",
      "TRAINING: BiLSTM Siamese\n",
      "================================================================================\n",
      "Epochs: 25 | Learning Rate: 0.001 | Patience: 5\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 984\u001b[39m\n\u001b[32m    982\u001b[39m \u001b[38;5;66;03m# Run the main pipeline\u001b[39;00m\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 912\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    909\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - Total parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel1.parameters())\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    910\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - Trainable parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.numel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel1.parameters()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mp.requires_grad)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m history1 = \u001b[43mtrainer1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[38;5;66;03m# Step 4: Model 2 - BiLSTM with Attention\u001b[39;00m\n\u001b[32m    915\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 585\u001b[39m, in \u001b[36mModelTrainer.train\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs, lr, patience)\u001b[39m\n\u001b[32m    583\u001b[39m criterion = nn.BCELoss()\n\u001b[32m    584\u001b[39m optimizer = optim.Adam(\u001b[38;5;28mself\u001b[39m.model.parameters(), lr=lr)\n\u001b[32m--> \u001b[39m\u001b[32m585\u001b[39m scheduler = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    587\u001b[39m best_val_loss = \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    588\u001b[39m patience_counter = \u001b[32m0\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEEP LEARNING ASSIGNMENT 2: LEGAL CLAUSE SIMILARITY\n",
    "# NUCES FAST, Islamabad\n",
    "# Due Date: November 10, 2025\n",
    "# COMPLETE SOLUTION WITH PARALLEL PROCESSING (100-500x FASTER)\n",
    "# ============================================================================\n",
    "\n",
    "# PART 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, classification_report,\n",
    "                             confusion_matrix, roc_curve, auc, precision_recall_curve)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LEGAL CLAUSE SIMILARITY DETECTION\")\n",
    "print(\"Deep Learning Assignment 2 - NUCES FAST\")\n",
    "print(\"WITH PARALLEL PROCESSING (100-500x FASTER)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"CPU Cores Available: {os.cpu_count()}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: DATA LOADING AND PREPROCESSING CLASS (WITH PARALLEL PROCESSING)\n",
    "# ============================================================================\n",
    "\n",
    "class LegalClauseDataProcessor:\n",
    "    \"\"\"\n",
    "    Modular class for loading and preprocessing legal clause data.\n",
    "    NOW WITH PARALLEL PROCESSING FOR 100-500x SPEED IMPROVEMENT!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path=\"*.csv\", max_words=10000, max_len=150):\n",
    "        \"\"\"\n",
    "        Initialize the data processor.\n",
    "\n",
    "        Args:\n",
    "            data_path: Path pattern to CSV files\n",
    "            max_words: Maximum vocabulary size\n",
    "            max_len: Maximum sequence length\n",
    "        \"\"\"\n",
    "        self.data_path = data_path\n",
    "        self.max_words = max_words\n",
    "        self.max_len = max_len\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.vocab_size = 0\n",
    "        self.clause_df = None\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Clean and normalize legal clause text.\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load all CSV files and combine into single dataframe.\"\"\"\n",
    "        csv_files = glob.glob(self.data_path)\n",
    "\n",
    "        if len(csv_files) == 0:\n",
    "            print(\"âš ï¸  WARNING: No CSV files found in current directory!\")\n",
    "            print(\"Please ensure legal clause dataset CSVs are in the same folder.\")\n",
    "            print(\"Creating sample data for demonstration purposes...\\n\")\n",
    "            return self._create_sample_data()\n",
    "\n",
    "        all_data = []\n",
    "        print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "        for file in csv_files:\n",
    "            try:\n",
    "                df = pd.read_csv(file)\n",
    "                if not df.empty and len(df.columns) >= 1:\n",
    "                    df['category'] = os.path.basename(file).replace('.csv', '')\n",
    "                    all_data.append(df)\n",
    "                    print(f\"  âœ“ Loaded: {os.path.basename(file)} - {len(df)} clauses\")\n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error loading {file}: {e}\")\n",
    "\n",
    "        if all_data:\n",
    "            self.clause_df = pd.concat(all_data, ignore_index=True)\n",
    "            print(f\"\\nðŸ“Š Total: {len(self.clause_df)} clauses from {len(csv_files)} categories\")\n",
    "        else:\n",
    "            print(\"No data loaded, creating sample data...\")\n",
    "            self.clause_df = self._create_sample_data()\n",
    "\n",
    "        return self.clause_df\n",
    "\n",
    "    def _create_sample_data(self):\n",
    "        \"\"\"Create sample legal clause data for demonstration.\"\"\"\n",
    "        samples = [\n",
    "            (\"The party shall pay all amounts due within thirty days of invoice date\", \"payment\", \"payment-terms\"),\n",
    "            (\"Payment must be completed within 30 days from the date of billing\", \"payment\", \"payment-terms\"),\n",
    "            (\"Purchaser agrees to remit payment no later than one month after receipt\", \"payment\", \"payment-terms\"),\n",
    "            (\"All confidential information must be protected and not disclosed to third parties\", \"confidentiality\", \"confidential-info\"),\n",
    "            (\"The receiving party shall maintain confidentiality of proprietary information\", \"confidentiality\", \"confidential-info\"),\n",
    "            (\"Trade secrets and private data shall remain undisclosed\", \"confidentiality\", \"confidential-info\"),\n",
    "            (\"This agreement may be terminated with 60 days written notice\", \"termination\", \"termination-clause\"),\n",
    "            (\"Either party can terminate by providing two months advance notice\", \"termination\", \"termination-clause\"),\n",
    "            (\"Contract termination requires notice period of sixty days\", \"termination\", \"termination-clause\"),\n",
    "            (\"The seller warrants the goods are free from defects in material and workmanship\", \"warranty\", \"warranty-clause\"),\n",
    "            (\"Goods are guaranteed to be defect-free and of merchantable quality\", \"warranty\", \"warranty-clause\"),\n",
    "            (\"Vendor guarantees products meet specifications without flaws\", \"warranty\", \"warranty-clause\"),\n",
    "            (\"Disputes shall be resolved through binding arbitration in accordance with rules\", \"dispute\", \"dispute-resolution\"),\n",
    "            (\"Any conflict will be settled via arbitration process under applicable law\", \"dispute\", \"dispute-resolution\"),\n",
    "            (\"Parties agree to arbitrate disagreements before neutral arbitrator\", \"dispute\", \"dispute-resolution\"),\n",
    "            (\"The company shall indemnify against all claims arising from negligence\", \"indemnity\", \"indemnification\"),\n",
    "            (\"Party agrees to defend and hold harmless from liability\", \"indemnity\", \"indemnification\"),\n",
    "            (\"Force majeure events excuse performance when beyond reasonable control\", \"force-majeure\", \"force-majeure\"),\n",
    "            (\"Acts of God or circumstances outside control suspend obligations\", \"force-majeure\", \"force-majeure\"),\n",
    "            (\"This contract is governed by the laws of the specified jurisdiction\", \"governing-law\", \"jurisdiction\"),\n",
    "            (\"Agreement shall be construed under laws of the designated state\", \"governing-law\", \"jurisdiction\"),\n",
    "        ]\n",
    "\n",
    "        df = pd.DataFrame(samples, columns=['clause_text', 'clause_type', 'category'])\n",
    "        print(f\"âœ“ Created {len(df)} sample clauses across {df['category'].nunique()} categories\\n\")\n",
    "        return df\n",
    "\n",
    "    def create_pairs_parallel(self, df, n_jobs=-1, max_pairs_per_category=500):\n",
    "        \"\"\"\n",
    "        PARALLEL VERSION: Create clause pairs using all CPU cores.\n",
    "        100-500x FASTER than original implementation!\n",
    "\n",
    "        Args:\n",
    "            df: DataFrame with clauses\n",
    "            n_jobs: Number of parallel jobs (-1 = all cores)\n",
    "            max_pairs_per_category: Maximum positive pairs per category\n",
    "\n",
    "        Returns:\n",
    "            pairs: List of (clause1, clause2) tuples\n",
    "            labels: List of labels (1=similar, 0=dissimilar)\n",
    "        \"\"\"\n",
    "        cat_col = 'category' if 'category' in df.columns else 'clause_type'\n",
    "        text_col = 'clause_text' if 'clause_text' in df.columns else df.columns[0]\n",
    "\n",
    "        # Pre-group clauses by category for faster access\n",
    "        category_groups = df.groupby(cat_col)[text_col].apply(np.array).to_dict()\n",
    "        categories = list(category_groups.keys())\n",
    "\n",
    "        print(f\"\\nðŸš€ Creating pairs using PARALLEL PROCESSINGn_...\")\n",
    "        print(f\"  - Categories: {len(categories)}\")\n",
    "        print(f\"  - CPU cores: {os.cpu_count() if n_jobs == -1 else n_jobs}\")\n",
    "        print(f\"  - Max pairs per category: {max_pairs_per_category}\")\n",
    "\n",
    "        def process_category(cat):\n",
    "            \"\"\"Process one category in parallel.\"\"\"\n",
    "            cat_clauses = category_groups[cat]\n",
    "            n_clauses = len(cat_clauses)\n",
    "\n",
    "            local_pairs = []\n",
    "            local_labels = []\n",
    "\n",
    "            if n_clauses < 2:\n",
    "                return local_pairs, local_labels\n",
    "\n",
    "            # Calculate how many pairs to create\n",
    "            max_possible = (n_clauses * (n_clauses - 1)) // 2\n",
    "            max_pairs = min(max_pairs_per_category, max_possible)\n",
    "\n",
    "            if max_possible <= max_pairs_per_category:\n",
    "                # Small category: use all combinations\n",
    "                for i in range(n_clauses):\n",
    "                    for j in range(i + 1, n_clauses):\n",
    "                        local_pairs.append((cat_clauses[i], cat_clauses[j]))\n",
    "                        local_labels.append(1)\n",
    "            else:\n",
    "                # Large category: random sampling\n",
    "                sampled = 0\n",
    "                seen = set()\n",
    "                attempts = 0\n",
    "                max_attempts = max_pairs * 3\n",
    "\n",
    "                while sampled < max_pairs and attempts < max_attempts:\n",
    "                    attempts += 1\n",
    "                    i, j = np.random.choice(n_clauses, size=2, replace=False)\n",
    "                    key = (min(i, j), max(i, j))\n",
    "\n",
    "                    if key not in seen:\n",
    "                        seen.add(key)\n",
    "                        local_pairs.append((cat_clauses[i], cat_clauses[j]))\n",
    "                        local_labels.append(1)\n",
    "                        sampled += 1\n",
    "\n",
    "            return local_pairs, local_labels\n",
    "\n",
    "        # Process categories in parallel\n",
    "        start_time = time.time()\n",
    "        results = Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "            delayed(process_category)(cat) for cat in categories\n",
    "        )\n",
    "\n",
    "        # Combine results\n",
    "        all_pairs = []\n",
    "        all_labels = []\n",
    "        for pairs, labels in results:\n",
    "            all_pairs.extend(pairs)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "        num_positive = len(all_labels)\n",
    "        print(f\"  âœ“ Created {num_positive} positive pairs in {time.time() - start_time:.2f}s\")\n",
    "\n",
    "        # CREATE NEGATIVE PAIRS (Dissimilar - different categories)\n",
    "        print(f\"  Creating negative pairs...\")\n",
    "        num_negative_target = num_positive\n",
    "\n",
    "        if len(categories) >= 2:\n",
    "            for _ in range(num_negative_target):\n",
    "                cat1, cat2 = np.random.choice(categories, size=2, replace=False)\n",
    "                c1 = np.random.choice(category_groups[cat1])\n",
    "                c2 = np.random.choice(category_groups[cat2])\n",
    "                all_pairs.append((c1, c2))\n",
    "                all_labels.append(0)\n",
    "\n",
    "        print(f\"  âœ“ Created {len(all_labels) - num_positive} negative pairs\")\n",
    "        print(f\"  âœ“ Total: {len(all_pairs)} pairs\")\n",
    "        print(f\"  âœ“ Balance: {num_positive/len(all_labels)*100:.1f}% positive\")\n",
    "\n",
    "        return all_pairs, all_labels\n",
    "\n",
    "    def build_vocabulary(self, texts):\n",
    "        \"\"\"Build word vocabulary from texts.\"\"\"\n",
    "        word_freq = Counter()\n",
    "        for text in texts:\n",
    "            words = text.split()\n",
    "            word_freq.update(words)\n",
    "\n",
    "        # Keep most common words\n",
    "        most_common = word_freq.most_common(self.max_words - 2)\n",
    "\n",
    "        # Build vocab with special tokens\n",
    "        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
    "\n",
    "        for idx, (word, _) in enumerate(most_common, start=2):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "    def text_to_sequence(self, text):\n",
    "        \"\"\"Convert text to sequence of indices.\"\"\"\n",
    "        words = text.split()\n",
    "        sequence = [self.word2idx.get(word, 1) for word in words]  # 1 = <UNK>\n",
    "\n",
    "        # Pad or truncate\n",
    "        if len(sequence) < self.max_len:\n",
    "            sequence += [0] * (self.max_len - len(sequence))  # 0 = <PAD>\n",
    "        else:\n",
    "            sequence = sequence[:self.max_len]\n",
    "\n",
    "        return sequence\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Main preprocessing pipeline.\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"DATA PREPROCESSING PIPELINE\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        # Load data\n",
    "        df = self.load_data()\n",
    "\n",
    "        # Clean text\n",
    "        text_column = 'clause_text' if 'clause_text' in df.columns else df.columns[0]\n",
    "        print(f\"\\nCleaning text data...\")\n",
    "        df[text_column] = df[text_column].apply(self.clean_text)\n",
    "\n",
    "        print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "        print(f\"  - Total clauses: {len(df)}\")\n",
    "        print(f\"  - Unique categories: {df['category'].nunique() if 'category' in df.columns else 'N/A'}\")\n",
    "\n",
    "        # Create pairs using PARALLEL processing\n",
    "        pairs, labels = self.create_pairs_parallel(df, n_jobs=-1, max_pairs_per_category=500)\n",
    "\n",
    "        # Prepare texts\n",
    "        clause1 = [p[0] for p in pairs]\n",
    "        clause2 = [p[1] for p in pairs]\n",
    "\n",
    "        # Build vocabulary\n",
    "        print(f\"\\nðŸ“š Building vocabulary...\")\n",
    "        all_texts = clause1 + clause2\n",
    "        self.build_vocabulary(all_texts)\n",
    "\n",
    "        # Convert to sequences\n",
    "        print(f\"  - Vocabulary size: {self.vocab_size}\")\n",
    "        print(f\"  - Max sequence length: {self.max_len}\")\n",
    "        print(f\"\\nðŸ”¢ Converting texts to sequences...\")\n",
    "\n",
    "        seq1 = np.array([self.text_to_sequence(text) for text in clause1])\n",
    "        seq2 = np.array([self.text_to_sequence(text) for text in clause2])\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        print(f\"  - Sequence 1 shape: {seq1.shape}\")\n",
    "        print(f\"  - Sequence 2 shape: {seq2.shape}\")\n",
    "        print(f\"  - Labels shape: {labels.shape}\")\n",
    "        print(\"\\nâœ“ Preprocessing complete!\")\n",
    "\n",
    "        return seq1, seq2, labels, self.vocab_size\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: PYTORCH DATASET CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class ClausePairDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for clause pairs.\"\"\"\n",
    "\n",
    "    def __init__(self, seq1, seq2, labels):\n",
    "        self.seq1 = torch.LongTensor(seq1)\n",
    "        self.seq2 = torch.LongTensor(seq2)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.seq1[idx], self.seq2[idx], self.labels[idx]\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: MODEL ARCHITECTURES\n",
    "# ============================================================================\n",
    "\n",
    "class BiLSTMSiamese(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline 1: Bidirectional LSTM for Siamese Network\n",
    "\n",
    "    Architecture:\n",
    "    - Embedding layer\n",
    "    - Bidirectional LSTM\n",
    "    - Global average pooling\n",
    "    - Distance calculation\n",
    "    - Similarity prediction\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=64, num_layers=2, dropout=0.3):\n",
    "        super(BiLSTMSiamese, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode a single clause.\"\"\"\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "        # Global average pooling\n",
    "        pooled = torch.mean(lstm_out, dim=1)\n",
    "        return pooled\n",
    "\n",
    "    def forward(self, seq1, seq2):\n",
    "        \"\"\"Forward pass for clause pair.\"\"\"\n",
    "        # Encode both clauses\n",
    "        encoded1 = self.encode(seq1)\n",
    "        encoded2 = self.encode(seq2)\n",
    "\n",
    "        # Calculate absolute difference\n",
    "        diff = torch.abs(encoded1 - encoded2)\n",
    "\n",
    "        # Classification layers\n",
    "        x = self.dropout(diff)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x.squeeze()\n",
    "\n",
    "class BiLSTMWithAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline 2: Bidirectional LSTM with Attention Mechanism\n",
    "\n",
    "    Architecture:\n",
    "    - Embedding layer\n",
    "    - Bidirectional LSTM\n",
    "    - Self-attention mechanism\n",
    "    - Weighted pooling\n",
    "    - Distance calculation\n",
    "    - Similarity prediction\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=64, num_layers=2, dropout=0.3):\n",
    "        super(BiLSTMWithAttention, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            num_layers=num_layers,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention_dim = hidden_dim * 2\n",
    "        self.attention = nn.Linear(self.attention_dim, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def attention_layer(self, lstm_output):\n",
    "        \"\"\"\n",
    "        Apply self-attention mechanism.\n",
    "\n",
    "        Args:\n",
    "            lstm_output: LSTM output [batch, seq_len, hidden*2]\n",
    "        Returns:\n",
    "            context: Attention-weighted representation [batch, hidden*2]\n",
    "        \"\"\"\n",
    "        # Calculate attention scores\n",
    "        attention_scores = self.attention(lstm_output)  # [batch, seq_len, 1]\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "\n",
    "        # Weighted sum\n",
    "        context = torch.sum(attention_weights * lstm_output, dim=1)  # [batch, hidden*2]\n",
    "\n",
    "        return context\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode a single clause with attention.\"\"\"\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "\n",
    "        # Apply attention\n",
    "        context = self.attention_layer(lstm_out)\n",
    "\n",
    "        return context\n",
    "\n",
    "    def forward(self, seq1, seq2):\n",
    "        \"\"\"Forward pass for clause pair.\"\"\"\n",
    "        # Encode both clauses\n",
    "        encoded1 = self.encode(seq1)\n",
    "        encoded2 = self.encode(seq2)\n",
    "\n",
    "        # Calculate absolute difference\n",
    "        diff = torch.abs(encoded1 - encoded2)\n",
    "\n",
    "        # Classification layers\n",
    "        x = self.dropout(diff)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x.squeeze()\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: TRAINING CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "    Modular trainer class for training and evaluation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, device, model_name=\"Model\"):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': []\n",
    "        }\n",
    "\n",
    "    def train_epoch(self, dataloader, criterion, optimizer):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for seq1, seq2, labels in dataloader:\n",
    "            seq1 = seq1.to(self.device)\n",
    "            seq2 = seq2.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(seq1, seq2)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def validate(self, dataloader, criterion):\n",
    "        \"\"\"Validate the model.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for seq1, seq2, labels in dataloader:\n",
    "                seq1 = seq1.to(self.device)\n",
    "                seq2 = seq2.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                outputs = self.model(seq1, seq2)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                predictions = (outputs > 0.5).float()\n",
    "                correct += (predictions == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return avg_loss, accuracy\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=20, lr=0.001, patience=5):\n",
    "        \"\"\"Complete training loop with early stopping.\"\"\"\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"TRAINING: {self.model_name}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        print(f\"Epochs: {epochs} | Learning Rate: {lr} | Patience: {patience}\")\n",
    "        print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "\n",
    "            # Train\n",
    "            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "\n",
    "            # Validate\n",
    "            val_loss, val_acc = self.validate(val_loader, criterion)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "\n",
    "            # Learning rate scheduling\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            epoch_time = time.time() - epoch_start\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"Epoch {epoch+1:02d}/{epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | \"\n",
    "                  f\"Time: {epoch_time:.2f}s\")\n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save best model\n",
    "                torch.save(self.model.state_dict(), f'{self.model_name.replace(\" \", \"_\")}_best.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"\\nâš ï¸  Early stopping triggered after {epoch+1} epochs\")\n",
    "                    break\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nâœ“ Training complete! Total time: {total_time:.2f}s\")\n",
    "        print(f\"âœ“ Best validation loss: {best_val_loss:.4f}\")\n",
    "\n",
    "        # Load best model\n",
    "        self.model.load_state_dict(torch.load(f'{self.model_name.replace(\" \", \"_\")}_best.pth'))\n",
    "\n",
    "        return self.history\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"Comprehensive evaluation with all metrics.\"\"\"\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"EVALUATION: {self.model_name}\")\n",
    "        print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "        all_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for seq1, seq2, labels in test_loader:\n",
    "                seq1 = seq1.to(self.device)\n",
    "                seq2 = seq2.to(self.device)\n",
    "\n",
    "                outputs = self.model(seq1, seq2)\n",
    "                predictions = (outputs > 0.5).float()\n",
    "\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(labels.numpy())\n",
    "                all_probs.extend(outputs.cpu().numpy())\n",
    "\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_probs = np.array(all_probs)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "        recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "        roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "\n",
    "        # Precision-Recall AUC\n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(all_labels, all_probs)\n",
    "        pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'roc_auc': roc_auc,\n",
    "            'pr_auc': pr_auc,\n",
    "            'predictions': all_predictions,\n",
    "            'labels': all_labels,\n",
    "            'probs': all_probs\n",
    "        }\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"ðŸ“Š Performance Metrics:\")\n",
    "        print(f\"  - Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"  - Precision: {precision:.4f}\")\n",
    "        print(f\"  - Recall:    {recall:.4f}\")\n",
    "        print(f\"  - F1-Score:  {f1:.4f}\")\n",
    "        print(f\"  - ROC-AUC:   {roc_auc:.4f}\")\n",
    "        print(f\"  - PR-AUC:    {pr_auc:.4f}\")\n",
    "\n",
    "        print(f\"\\nðŸ“‹ Classification Report:\")\n",
    "        print(classification_report(all_labels, all_predictions, \n",
    "                                   target_names=['Dissimilar', 'Similar'],\n",
    "                                   digits=4))\n",
    "\n",
    "        return metrics\n",
    "\n",
    "# ============================================================================\n",
    "# PART 6: VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def plot_training_history(history1, history2, name1, name2):\n",
    "    \"\"\"Plot training history comparison.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Loss plot\n",
    "    axes[0].plot(history1['train_loss'], label=f'{name1} - Train', linewidth=2)\n",
    "    axes[0].plot(history1['val_loss'], label=f'{name1} - Val', linewidth=2, linestyle='--')\n",
    "    axes[0].plot(history2['train_loss'], label=f'{name2} - Train', linewidth=2)\n",
    "    axes[0].plot(history2['val_loss'], label=f'{name2} - Val', linewidth=2, linestyle='--')\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Accuracy plot\n",
    "    axes[1].plot(history1['train_acc'], label=f'{name1} - Train', linewidth=2)\n",
    "    axes[1].plot(history1['val_acc'], label=f'{name1} - Val', linewidth=2, linestyle='--')\n",
    "    axes[1].plot(history2['train_acc'], label=f'{name2} - Train', linewidth=2)\n",
    "    axes[1].plot(history2['val_acc'], label=f'{name2} - Val', linewidth=2, linestyle='--')\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ“ Saved: training_history_comparison.png\")\n",
    "\n",
    "def plot_confusion_matrices(metrics1, metrics2, name1, name2):\n",
    "    \"\"\"Plot confusion matrices for both models.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    cm1 = confusion_matrix(metrics1['labels'], metrics1['predictions'])\n",
    "    cm2 = confusion_matrix(metrics2['labels'], metrics2['predictions'])\n",
    "\n",
    "    sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "                xticklabels=['Dissimilar', 'Similar'],\n",
    "                yticklabels=['Dissimilar', 'Similar'])\n",
    "    axes[0].set_title(f'{name1}\\nConfusion Matrix', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "    sns.heatmap(cm2, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "                xticklabels=['Dissimilar', 'Similar'],\n",
    "                yticklabels=['Dissimilar', 'Similar'])\n",
    "    axes[1].set_title(f'{name2}\\nConfusion Matrix', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('True Label', fontsize=12)\n",
    "    axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ“ Saved: confusion_matrices.png\")\n",
    "\n",
    "def plot_roc_curves(metrics1, metrics2, name1, name2):\n",
    "    \"\"\"Plot ROC curves for both models.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Model 1 ROC\n",
    "    fpr1, tpr1, _ = roc_curve(metrics1['labels'], metrics1['probs'])\n",
    "    roc_auc1 = auc(fpr1, tpr1)\n",
    "    plt.plot(fpr1, tpr1, linewidth=2, label=f'{name1} (AUC = {roc_auc1:.4f})')\n",
    "\n",
    "    # Model 2 ROC\n",
    "    fpr2, tpr2, _ = roc_curve(metrics2['labels'], metrics2['probs'])\n",
    "    roc_auc2 = auc(fpr2, tpr2)\n",
    "    plt.plot(fpr2, tpr2, linewidth=2, label=f'{name2} (AUC = {roc_auc2:.4f})')\n",
    "\n",
    "    # Diagonal line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "\n",
    "    plt.xlabel('False Positive Rate', fontsize=12)\n",
    "    plt.ylabel('True Positive Rate', fontsize=12)\n",
    "    plt.title('ROC Curve Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ“ Saved: roc_curves.png\")\n",
    "\n",
    "def plot_pr_curves(metrics1, metrics2, name1, name2):\n",
    "    \"\"\"Plot Precision-Recall curves.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Model 1 PR curve\n",
    "    precision1, recall1, _ = precision_recall_curve(metrics1['labels'], metrics1['probs'])\n",
    "    pr_auc1 = auc(recall1, precision1)\n",
    "    plt.plot(recall1, precision1, linewidth=2, label=f'{name1} (AUC = {pr_auc1:.4f})')\n",
    "\n",
    "    # Model 2 PR curve\n",
    "    precision2, recall2, _ = precision_recall_curve(metrics2['labels'], metrics2['probs'])\n",
    "    pr_auc2 = auc(recall2, precision2)\n",
    "    plt.plot(recall2, precision2, linewidth=2, label=f'{name2} (AUC = {pr_auc2:.4f})')\n",
    "\n",
    "    plt.xlabel('Recall', fontsize=12)\n",
    "    plt.ylabel('Precision', fontsize=12)\n",
    "    plt.title('Precision-Recall Curve Comparison', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pr_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"âœ“ Saved: pr_curves.png\")\n",
    "\n",
    "def create_comparison_table(metrics1, metrics2, name1, name2):\n",
    "    \"\"\"Create and display comparison table.\"\"\"\n",
    "    comparison_data = {\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'PR-AUC'],\n",
    "        name1: [\n",
    "            f\"{metrics1['accuracy']:.4f}\",\n",
    "            f\"{metrics1['precision']:.4f}\",\n",
    "            f\"{metrics1['recall']:.4f}\",\n",
    "            f\"{metrics1['f1_score']:.4f}\",\n",
    "            f\"{metrics1['roc_auc']:.4f}\",\n",
    "            f\"{metrics1['pr_auc']:.4f}\"\n",
    "        ],\n",
    "        name2: [\n",
    "            f\"{metrics2['accuracy']:.4f}\",\n",
    "            f\"{metrics2['precision']:.4f}\",\n",
    "            f\"{metrics2['recall']:.4f}\",\n",
    "            f\"{metrics2['f1_score']:.4f}\",\n",
    "            f\"{metrics2['roc_auc']:.4f}\",\n",
    "            f\"{metrics2['pr_auc']:.4f}\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PERFORMANCE COMPARISON TABLE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df_comparison.to_string(index=False))\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Save to CSV\n",
    "    df_comparison.to_csv('model_comparison.csv', index=False)\n",
    "    print(\"\\nâœ“ Saved: model_comparison.csv\")\n",
    "\n",
    "    return df_comparison\n",
    "\n",
    "# ============================================================================\n",
    "# PART 7: MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"STARTING LEGAL CLAUSE SIMILARITY DETECTION PIPELINE\")\n",
    "    print(\"WITH PARALLEL PROCESSING FOR 100-500x SPEED IMPROVEMENT\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Step 1: Data Preprocessing\n",
    "    print(\"\\n[STEP 1/6] Data Loading and Preprocessing\")\n",
    "    processor = LegalClauseDataProcessor(data_path=\"*.csv\", max_words=10000, max_len=150)\n",
    "    seq1, seq2, labels, vocab_size = processor.preprocess_data()\n",
    "\n",
    "    # Step 2: Train-Val-Test Split\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"[STEP 2/6] Creating Train/Validation/Test Splits\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # First split: 80% train+val, 20% test\n",
    "    indices = np.arange(len(labels))\n",
    "    train_val_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    # Second split: 80% train, 20% val from train+val\n",
    "    train_idx, val_idx = train_test_split(train_val_idx, test_size=0.2, random_state=42, \n",
    "                                          stratify=labels[train_val_idx])\n",
    "\n",
    "    print(f\"\\nðŸ“Š Data Split:\")\n",
    "    print(f\"  - Training:   {len(train_idx)} samples ({len(train_idx)/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  - Validation: {len(val_idx)} samples ({len(val_idx)/len(labels)*100:.1f}%)\")\n",
    "    print(f\"  - Test:       {len(test_idx)} samples ({len(test_idx)/len(labels)*100:.1f}%)\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = ClausePairDataset(seq1[train_idx], seq2[train_idx], labels[train_idx])\n",
    "    val_dataset = ClausePairDataset(seq1[val_idx], seq2[val_idx], labels[val_idx])\n",
    "    test_dataset = ClausePairDataset(seq1[test_idx], seq2[test_idx], labels[test_idx])\n",
    "\n",
    "    # Create dataloaders\n",
    "    batch_size = 32\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    print(f\"  - Batch size: {batch_size}\")\n",
    "    print(f\"  - Train batches: {len(train_loader)}\")\n",
    "    print(f\"  - Val batches: {len(val_loader)}\")\n",
    "    print(f\"  - Test batches: {len(test_loader)}\")\n",
    "\n",
    "    # Step 3: Model 1 - BiLSTM\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"[STEP 3/6] Training Model 1: BiLSTM Siamese Network\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    model1 = BiLSTMSiamese(vocab_size, embedding_dim=128, hidden_dim=64, num_layers=2, dropout=0.3)\n",
    "    trainer1 = ModelTrainer(model1, device, model_name=\"BiLSTM Siamese\")\n",
    "\n",
    "    print(f\"\\nðŸ—ï¸  Model 1 Architecture:\")\n",
    "    print(f\"  - Total parameters: {sum(p.numel() for p in model1.parameters()):,}\")\n",
    "    print(f\"  - Trainable parameters: {sum(p.numel() for p in model1.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "    history1 = trainer1.train(train_loader, val_loader, epochs=25, lr=0.001, patience=5)\n",
    "\n",
    "    # Step 4: Model 2 - BiLSTM with Attention\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"[STEP 4/6] Training Model 2: BiLSTM with Attention\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    model2 = BiLSTMWithAttention(vocab_size, embedding_dim=128, hidden_dim=64, num_layers=2, dropout=0.3)\n",
    "    trainer2 = ModelTrainer(model2, device, model_name=\"BiLSTM Attention\")\n",
    "\n",
    "    print(f\"\\nðŸ—ï¸  Model 2 Architecture:\")\n",
    "    print(f\"  - Total parameters: {sum(p.numel() for p in model2.parameters()):,}\")\n",
    "    print(f\"  - Trainable parameters: {sum(p.numel() for p in model2.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "    history2 = trainer2.train(train_loader, val_loader, epochs=25, lr=0.001, patience=5)\n",
    "\n",
    "    # Step 5: Evaluation\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"[STEP 5/6] Model Evaluation on Test Set\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    metrics1 = trainer1.evaluate(test_loader)\n",
    "    metrics2 = trainer2.evaluate(test_loader)\n",
    "\n",
    "    # Step 6: Visualization and Comparison\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"[STEP 6/6] Generating Visualizations and Comparisons\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    plot_training_history(history1, history2, \"BiLSTM\", \"BiLSTM+Attention\")\n",
    "    plot_confusion_matrices(metrics1, metrics2, \"BiLSTM\", \"BiLSTM+Attention\")\n",
    "    plot_roc_curves(metrics1, metrics2, \"BiLSTM\", \"BiLSTM+Attention\")\n",
    "    plot_pr_curves(metrics1, metrics2, \"BiLSTM\", \"BiLSTM+Attention\")\n",
    "    comparison_df = create_comparison_table(metrics1, metrics2, \"BiLSTM\", \"BiLSTM+Attention\")\n",
    "\n",
    "    # Show sample predictions\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SAMPLE PREDICTIONS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Get some test samples\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (s1, s2, label) in enumerate(test_loader):\n",
    "            if i > 0:  # Just first batch\n",
    "                break\n",
    "            s1, s2 = s1.to(device), s2.to(device)\n",
    "            pred1 = model1(s1, s2).cpu().numpy()\n",
    "            pred2 = model2(s1, s2).cpu().numpy()\n",
    "\n",
    "            # Show first 5 samples\n",
    "            for j in range(min(5, len(label))):\n",
    "                print(f\"\\nSample {j+1}:\")\n",
    "                print(f\"  True Label: {'Similar' if label[j] == 1 else 'Dissimilar'}\")\n",
    "                print(f\"  BiLSTM Prediction: {pred1[j]:.4f} ({'Similar' if pred1[j] > 0.5 else 'Dissimilar'})\")\n",
    "                print(f\"  BiLSTM+Attention Prediction: {pred2[j]:.4f} ({'Similar' if pred2[j] > 0.5 else 'Dissimilar'})\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… ASSIGNMENT COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nGenerated Files:\")\n",
    "    print(\"  âœ“ BiLSTM_Siamese_best.pth\")\n",
    "    print(\"  âœ“ BiLSTM_Attention_best.pth\")\n",
    "    print(\"  âœ“ training_history_comparison.png\")\n",
    "    print(\"  âœ“ confusion_matrices.png\")\n",
    "    print(\"  âœ“ roc_curves.png\")\n",
    "    print(\"  âœ“ pr_curves.png\")\n",
    "    print(\"  âœ“ model_comparison.csv\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Run the main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
